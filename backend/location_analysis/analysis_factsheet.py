"""
AnalysisFactSheet - Single Source of Truth for AI and UI.

This module defines the canonical data structure that:
1. Is the ONLY input to AI text generation
2. Is generated by deterministic scoring engine
3. Ensures consistency between UI and AI narratives
"""
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any


@dataclass
class CategoryDriver:
    """A single category's contribution to the score."""
    category: str
    category_name: str
    grade: str  # 'excellent', 'good', 'moderate', 'poor', 'missing'
    nearest_m: Optional[int] = None
    count: int = 0
    score_delta: float = 0.0  # positive = bonus, negative = penalty
    detail: str = ""


@dataclass
class AppliedCap:
    """A scoring cap that was applied."""
    reason: str  # e.g., "car_access_missing"
    original_score: float
    capped_score: float
    threshold: float = 0.0
    explanation: str = ""


@dataclass
class AnalysisFactSheet:
    """
    Canonical 'single source of truth' for AI and UI.
    
    This is the ONLY object that AI receives. It contains only:
    - Computed facts (not raw POI data)
    - Deterministic decisions from scoring engine
    - Quality flags about input data
    
    AI should NEVER receive:
    - Raw POI lists
    - Intermediate calculations
    - Debug logs
    """
    
    # Profile context
    profile_key: str
    profile_name: str
    profile_emoji: str
    
    # Verdict (computed by engine, not AI)
    final_score: int
    verdict: str  # 'recommended', 'conditional', 'not_recommended'
    verdict_label: str  # Polish label for UI
    confidence: int
    
    # Primary blocker (if any) - THE reason score is capped/limited
    primary_blocker: Optional[str] = None  # e.g., "noise", "car_access"
    primary_blocker_detail: Optional[str] = None  # e.g., "Wysoki ruch na gÅ‚Ã³wnej arterii"
    
    # Top positive drivers (what helped the score)
    positive_drivers: List[CategoryDriver] = field(default_factory=list)
    
    # Top negative drivers (what hurt the score)
    negative_drivers: List[CategoryDriver] = field(default_factory=list)
    
    # All category grades (for completeness)
    category_grades: Dict[str, str] = field(default_factory=dict)
    
    # Caps/limits that were applied
    caps_applied: List[AppliedCap] = field(default_factory=list)
    
    # Data quality issues (triggers disclaimer in AI output)
    data_quality_flags: List[str] = field(default_factory=list)
    # Examples: "low_price_data", "plus_code_address", "missing_description", "incomplete_location"
    
    # Noise/traffic level (single canonical value)
    noise_level: str = "unknown"  # 'low', 'moderate', 'high', 'extreme'
    noise_source: str = ""  # e.g., "roads_analysis", "quiet_score"
    
    # Penalties from scoring engine (for deterministic decisions)
    penalties: Dict[str, float] = field(default_factory=dict)
    # e.g., {'noise_penalty': 2.5, 'roads_penalty': 12.0}
    
    # Roads debug info (for detailed noise risk assessment)
    roads_debug: Dict[str, Any] = field(default_factory=dict)
    # e.g., {'nearest_rails_m': 85, 'nearest_heavy_m': 450, 'count': 8}
    
    # Verdict reasons (deterministic, not AI-generated)
    verdict_reason: Optional[str] = None  # Why this verdict (scoring-based)
    data_reason: List[str] = field(default_factory=list)  # Coverage gaps / empty signals
    
    # Property data (optional, from user input)
    property_data: Optional[Dict[str, Any]] = None
    
    def to_ai_prompt_json(self) -> Dict[str, Any]:
        """
        Convert to JSON for AI prompt input.
        This is the ONLY representation AI sees.
        """
        return {
            "profile": {
                "key": self.profile_key,
                "name": self.profile_name,
                "emoji": self.profile_emoji,
            },
            "verdict": {
                "score": self.final_score,
                "level": self.verdict,
                "label": self.verdict_label,
                "confidence": self.confidence,
                "reason": self.verdict_reason,  # Deterministic reason for verdict
            },
            "primary_blocker": {
                "category": self.primary_blocker,
                "detail": self.primary_blocker_detail,
            } if self.primary_blocker else None,
            "positive_drivers": [
                {
                    "category": d.category,
                    "name": d.category_name,
                    "grade": d.grade,
                    "nearest_m": d.nearest_m,
                    "detail": d.detail,
                }
                for d in self.positive_drivers[:3]
            ],
            "negative_drivers": [
                {
                    "category": d.category,
                    "name": d.category_name,
                    "grade": d.grade,
                    "detail": d.detail,
                }
                for d in self.negative_drivers[:2]
            ],
            "noise": {
                "level": self.noise_level,
                "source": self.noise_source,
            },
            "penalties": self.penalties,  # {noise_penalty, roads_penalty}
            "roads_debug": self.roads_debug,  # Infrastructure proximity details
            "caps_applied": [
                {
                    "reason": c.reason,
                    "original": c.original_score,
                    "capped": c.capped_score,
                    "explanation": c.explanation,
                }
                for c in self.caps_applied
            ],
            "data_quality_flags": self.data_quality_flags,
            "data_reason": self.data_reason,  # Empty signals / coverage gaps
            # Property data (optional) - AI can mention if provided
            "property": self.property_data if self.property_data else None,
        }


def build_factsheet_from_scoring(
    profile,
    scoring_result,
    verdict,
    quiet_score: float,
    pois_by_category: Dict = None,
    listing = None,
    data_quality: Optional[Dict[str, Any]] = None,  # NEW: for empty signals
) -> AnalysisFactSheet:
    """
    Build AnalysisFactSheet from scoring engine output.
    
    This is the ONLY place where raw data is converted to factsheet.
    
    Args:
        data_quality: Dict with 'empty', 'errors', 'fallback_contributed' from data_quality pipeline
    """
    # Determine noise level from quiet_score
    if quiet_score >= 80:
        noise_level = "low"
    elif quiet_score >= 60:
        noise_level = "moderate"
    elif quiet_score >= 40:
        noise_level = "high"
    else:
        noise_level = "extreme"
    
    # Extract penalties directly from scoring_result fields (not from debug!)
    penalties = {
        'noise_penalty': getattr(scoring_result, 'noise_penalty', 0.0) or 0.0,
        'roads_penalty': getattr(scoring_result, 'roads_penalty', 0.0) or 0.0,
    }
    
    # Extract roads_debug directly from scoring_result (proper field, not debug dict)
    roads_debug = getattr(scoring_result, 'roads_debug', {}) or {}
    
    # Build positive drivers from strengths
    positive_drivers = []
    if hasattr(scoring_result, 'strengths') and scoring_result.strengths:
        for s in scoring_result.strengths[:3]:
            positive_drivers.append(CategoryDriver(
                category=s.lower().replace(' ', '_') if isinstance(s, str) else 'unknown',
                category_name=s if isinstance(s, str) else str(s),
                grade='good',
                detail=s if isinstance(s, str) else str(s),
            ))
    
    # Build negative drivers from weaknesses
    negative_drivers = []
    if hasattr(scoring_result, 'weaknesses') and scoring_result.weaknesses:
        for w in scoring_result.weaknesses[:2]:
            negative_drivers.append(CategoryDriver(
                category=w.lower().replace(' ', '_') if isinstance(w, str) else 'unknown',
                category_name=w if isinstance(w, str) else str(w),
                grade='poor',
                detail=w if isinstance(w, str) else str(w),
            ))
    
    # Build data_reason from data_quality pipeline (empty signals, errors)
    data_reason: List[str] = []
    if data_quality:
        empty_signals = data_quality.get('empty', []) or []
        for cat in empty_signals:
            data_reason.append(f"Brak danych: {cat}")
        
        errors = data_quality.get('errors', []) or []
        for err in errors:
            data_reason.append(f"BÅ‚Ä…d: {err}")
    
    # Detect data quality issues from listing (for disclaimer)
    # BUT: only for provider-sourced data, not user input
    data_quality_flags = []
    listing_source = getattr(listing, 'source', 'user') if listing else 'user'
    
    if listing and listing_source not in ('user', 'none'):
        # Only generate listing-specific warnings for provider data
        if not listing.description or len(listing.description) < 50:
            data_quality_flags.append("missing_description")
        if listing.price and listing.area_sqm:
            price_per_sqm = listing.price / listing.area_sqm
            if price_per_sqm < 3000 or price_per_sqm > 50000:
                data_quality_flags.append("suspicious_price_data")
        if listing.location and '+' in listing.location:
            data_quality_flags.append("plus_code_address")
    elif listing and listing_source == 'user':
        # For user input, only flag anomalies in provided data
        if listing.price and listing.area_sqm:
            price_per_sqm = listing.price / listing.area_sqm
            if price_per_sqm < 3000 or price_per_sqm > 50000:
                data_quality_flags.append("suspicious_price_data")
    
    # Build property_data for AI (only if user provided any data)
    property_data = None
    if listing and (listing.price or listing.area_sqm):
        property_data = {
            'source': listing_source,
            'price': listing.price,
            'area_sqm': listing.area_sqm,
            'price_per_sqm': round(listing.price / listing.area_sqm, 2) if (listing.price and listing.area_sqm) else None,
            'known': True,
        }
    
    # Add empty signals to data_quality_flags for AI disclaimer
    if data_quality:
        for cat in (data_quality.get('empty', []) or []):
            data_quality_flags.append(f"empty_signal:{cat}")
    
    # DETERMINISTIC primary_blocker selection (order matters!)
    # Priority: 1) data gaps, 2) roads infrastructure, 3) noise, 4) negative drivers
    ROADS_BLOCK_THRESHOLD = 8.0
    NOISE_BLOCK_THRESHOLD = 2.0
    
    primary_blocker = None
    primary_blocker_detail = None
    verdict_reason = None
    
    roads_penalty = penalties.get('roads_penalty', 0)
    noise_penalty = penalties.get('noise_penalty', 0)
    
    if data_reason:
        # 1. Data coverage gaps - highest priority
        primary_blocker = 'data'
        primary_blocker_detail = data_reason[0]
        verdict_reason = "NiepeÅ‚ne dane w kluczowej kategorii."
    elif roads_penalty >= ROADS_BLOCK_THRESHOLD:
        # 2. Roads infrastructure - noise risk
        primary_blocker = 'roads'
        rail_m = roads_debug.get('nearest_rails_m')
        primary_blocker_detail = f"BliskoÅ›Ä‡ drÃ³g/kolei (roads_penalty={roads_penalty:.1f})"
        if rail_m:
            primary_blocker_detail = f"BliskoÅ›Ä‡ drÃ³g/kolei (~{int(rail_m)}m do szyn)"
        verdict_reason = "Ryzyko podwyÅ¼szonego haÅ‚asu z infrastruktury drogowej."
    elif noise_penalty >= NOISE_BLOCK_THRESHOLD:
        # 3. Noise level
        primary_blocker = 'noise'
        primary_blocker_detail = f"Niska cisza (quiet_score={quiet_score:.0f}, noise_penalty={noise_penalty:.1f})"
        verdict_reason = "Poziom haÅ‚asu wymaga weryfikacji na miejscu."
    elif negative_drivers:
        # 4. First negative driver
        primary_blocker = negative_drivers[0].category
        primary_blocker_detail = negative_drivers[0].detail
        verdict_reason = f"SÅ‚aby wynik w kategorii: {negative_drivers[0].category_name}"
    
    # Map verdict level to Polish label
    verdict_labels = {
        'recommended': 'Polecane',
        'conditional': 'Polecane z kompromisem',
        'not_recommended': 'Nie polecane',
    }
    
    return AnalysisFactSheet(
        profile_key=profile.key if hasattr(profile, 'key') else 'unknown',
        profile_name=profile.name if hasattr(profile, 'name') else 'Profil',
        profile_emoji=profile.emoji if hasattr(profile, 'emoji') else 'ðŸ‘¤',
        final_score=int(scoring_result.total_score),
        verdict=verdict.level.value if hasattr(verdict.level, 'value') else str(verdict.level),
        verdict_label=verdict_labels.get(verdict.level.value if hasattr(verdict.level, 'value') else str(verdict.level), 'Ocenione'),
        confidence=verdict.confidence if hasattr(verdict, 'confidence') else 70,
        primary_blocker=primary_blocker,
        primary_blocker_detail=primary_blocker_detail,
        positive_drivers=positive_drivers,
        negative_drivers=negative_drivers,
        category_grades={},  # TODO: Fill from scoring_result
        caps_applied=[],  # TODO: Extract from scoring_result
        data_quality_flags=data_quality_flags,
        noise_level=noise_level,
        noise_source="quiet_score",
        penalties=penalties,
        roads_debug=roads_debug,
        verdict_reason=verdict_reason,
        data_reason=data_reason,
        property_data=property_data,
    )

